{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-14T13:26:48.779361Z",
     "start_time": "2025-12-14T13:26:47.980701Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.features import geometry_mask\n",
    "from shapely.geometry import mapping\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:26:48.788857Z",
     "start_time": "2025-12-14T13:26:48.785487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "HIMA_PATH = \"DATA_SV/Hima\"\n",
    "ERA5_PATH = \"DATA_SV/ERA5\"\n",
    "RADAR_PATH = \"DATA_SV/Precipitation/Radar\"\n",
    "\n",
    "OUTPUT_X = \"csv_data/tri_an_thanh_hoa/x.npy\"\n",
    "OUTPUT_Y = \"csv_data/tri_an_thanh_hoa/y.npy\"\n",
    "\n",
    "OUTPUT_RADAR_CSV = \"csv_data/tri_an_thanh_hoa/RADAR_CSV.csv\"\n",
    "OUTPUT_ERA5_CSV = \"csv_data/tri_an_thanh_hoa/ERA5_CSV.csv\"\n",
    "OUTPUT_HIMA_CSV = \"csv_data/tri_an_thanh_hoa/HIMA_CSV.csv\"\n",
    "\n",
    "selected_features = ['B04B', 'B10B', 'B11B', 'B16B', 'IRB',\n",
    "                     'CAPE', 'R850', 'TCWV', 'U850', 'I2B', 'TCLW', 'TCW']\n"
   ],
   "id": "2f89a680cb31b652",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:26:48.798827Z",
     "start_time": "2025-12-14T13:26:48.793965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# =========================================================\n",
    "# 2) TRÍCH DATETIME TỪ FILENAME\n",
    "# =========================================================\n",
    "def extract_datetime_from_filename(path):\n",
    "    filename = os.path.basename(path)\n",
    "\n",
    "    # Kiểu 1: CAPE_20190401000000.tif\n",
    "    m14 = re.search(r\"(\\d{14})\", filename)\n",
    "    if m14:\n",
    "        return pd.to_datetime(m14.group(1), format=\"%Y%m%d%H%M%S\", errors=\"coerce\")\n",
    "\n",
    "    # Kiểu 2: B04B_20190401.Z0000_TB.tif\n",
    "    m_date = re.search(r\"(\\d{8})\", filename)\n",
    "    m_z = re.search(r\"Z(\\d{4})\", filename)\n",
    "\n",
    "    if m_date:\n",
    "        date = m_date.group(1)\n",
    "        if m_z:\n",
    "            return pd.to_datetime(date + m_z.group(1), format=\"%Y%m%d%H%M\", errors=\"coerce\")\n",
    "        return pd.to_datetime(date, format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "    return pd.NaT\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3) LIST FILE\n",
    "# =========================================================\n",
    "def list_all_files(root):\n",
    "    out = []\n",
    "    for dp, _, files in os.walk(root):\n",
    "        for f in files:\n",
    "            if f.endswith(\".tif\") or f.endswith(\".TIF\"):\n",
    "                out.append(os.path.join(dp, f))\n",
    "    return out\n",
    "\n",
    "\n",
    "def fill_nodata_minus9999(arr):\n",
    "    \"\"\"\n",
    "    Fill toàn bộ NaN / +Inf / -Inf thành -9999\n",
    "    Nhanh, an toàn cho ML (XGBoost / CatBoost / LGBM)\n",
    "    \"\"\"\n",
    "    arr = arr.astype(np.float32, copy=False)\n",
    "    mask = np.isnan(arr) | np.isinf(arr)\n",
    "    if mask.any():\n",
    "        arr[mask] = -9999.0\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_variable_name(path):\n",
    "    \"\"\"\n",
    "    Lấy tên biến từ filename.\n",
    "    VD: 'B04B_2019....tif' -> trả về 'B04B'\n",
    "    VD: 'CAPE_2019....tif' -> trả về 'CAPE'\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(path)\n",
    "    return filename.split('_')[0]"
   ],
   "id": "9e5bff5f458b70a3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " Lấy các timestamp hợp lệ\n",
    " (tồn tại ở cả 3 folder ERA5, HIMA, RADAR và trong các band đã chọn)"
   ],
   "id": "6a691be000aa6d20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:26:48.809906Z",
     "start_time": "2025-12-14T13:26:48.804135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def get_final_common_timestamps(list_folders, selected_features):\n",
    "    \"\"\"\n",
    "    Chiến thuật:\n",
    "    1. Quét TOÀN BỘ file trong 3 folder (bất kể tên gì) để tìm giao điểm thời gian lớn nhất (cái 2337 mốc kia).\n",
    "    2. Sau khi có bộ khung thời gian chung, đi kiểm tra lại xem những giờ đó có đủ các feature B04B, CAPE... không.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- BƯỚC 1: QUÉT TẤT CẢ ĐỂ LẤY TIMESTAMP CHUNG (như bạn đã làm ra 2337) ---\n",
    "    print(f\"-> [B1] Quét toàn bộ 3 folder để tìm giao điểm thời gian...\")\n",
    "    list_sets = []\n",
    "\n",
    "    # Biến lưu trữ map: {timestamp: {variable_name: filepath}}\n",
    "    # Để tí nữa check feature cho nhanh, không cần scan lại\n",
    "    mega_map = {}\n",
    "\n",
    "    for folder in list_folders:\n",
    "        current_ts_set = set()\n",
    "        print(f\"   Scanning: {folder}...\")\n",
    "\n",
    "        for root, _, files in os.walk(folder):\n",
    "            for f in files:\n",
    "                if f.lower().endswith(('.tif', '.tiff')):\n",
    "                    fpath = os.path.join(root, f)\n",
    "                    ts = extract_datetime_from_filename(fpath)\n",
    "\n",
    "                    if pd.notna(ts):\n",
    "                        current_ts_set.add(ts)\n",
    "\n",
    "                        # Lưu lại thông tin file để dùng cho Bước 2\n",
    "                        # Lấy prefix làm tên biến (B04B, Radar, CAPE...)\n",
    "                        var_name = f.split('_')[0]\n",
    "\n",
    "                        # Mapping tên cho Radar (Quan trọng!)\n",
    "                        if var_name == 'Radar' or f.startswith('2019') or f.startswith('2020'):\n",
    "                            var_name = 'y'\n",
    "\n",
    "                        if ts not in mega_map: mega_map[ts] = set()\n",
    "                        mega_map[ts].add(var_name)\n",
    "\n",
    "        list_sets.append(current_ts_set)\n",
    "\n",
    "    # Giao nhau giữa 3 folder\n",
    "    if not list_sets: return []\n",
    "    common_ts = set.intersection(*list_sets)\n",
    "    sorted_common = sorted(list(common_ts))\n",
    "\n",
    "    print(f\"-> Đã tìm thấy {len(sorted_common)} mốc thời gian chung (Raw Intersection).\")\n",
    "\n",
    "    # --- BƯỚC 2: LỌC LẠI THEO FEATURE ---\n",
    "    # Bây giờ ta chỉ giữ lại những mốc thời gian mà tại đó có ĐỦ các feature yêu cầu\n",
    "\n",
    "    print(f\"-> [B2] Kiểm tra tính đầy đủ của Feature...\")\n",
    "    print(f\"   Yêu cầu: {selected_features} + ['y']\")\n",
    "\n",
    "    final_valid_ts = []\n",
    "\n",
    "    # Input feature + y\n",
    "    required_set = set(selected_features + ['y'])\n",
    "\n",
    "    for ts in sorted_common:\n",
    "        # Lấy danh sách các biến CÓ MẶT tại thời điểm ts\n",
    "        vars_at_ts = mega_map.get(ts, set())\n",
    "\n",
    "        # Kiểm tra xem có chứa đủ bộ required không\n",
    "        # Lưu ý: vars_at_ts có thể chứa nhiều biến rác khác, ta chỉ quan tâm nó có chứa đủ bộ required không thôi\n",
    "        if required_set.issubset(vars_at_ts):\n",
    "            final_valid_ts.append(ts)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(f\"✅ KẾT QUẢ CUỐI CÙNG: {len(final_valid_ts)} mốc thời gian ĐỦ DỮ LIỆU.\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    if len(final_valid_ts) == 0 and len(sorted_common) > 0:\n",
    "        print(\"⚠️ CẢNH BÁO: Có giao điểm thời gian nhưng bị thiếu Feature!\")\n",
    "        # Debug thử 1 mẫu\n",
    "        sample_ts = sorted_common[0]\n",
    "        print(f\"   Tại {sample_ts} có các biến: {mega_map[sample_ts]}\")\n",
    "        print(f\"   Thiếu: {required_set - mega_map[sample_ts]}\")\n",
    "\n",
    "    return final_valid_ts\n",
    "\n"
   ],
   "id": "435123a99837b9d3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:26:55.812329Z",
     "start_time": "2025-12-14T13:26:48.816878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FOLDERS = [HIMA_PATH, ERA5_PATH, RADAR_PATH]\n",
    "\n",
    "FINAL_TIMESTAMPS = get_final_common_timestamps(FOLDERS, selected_features)\n"
   ],
   "id": "63bc7e0b3bff131f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [B1] Quét toàn bộ 3 folder để tìm giao điểm thời gian...\n",
      "   Scanning: DATA_SV/Hima...\n",
      "   Scanning: DATA_SV/ERA5...\n",
      "   Scanning: DATA_SV/Precipitation/Radar...\n",
      "-> Đã tìm thấy 2337 mốc thời gian chung (Raw Intersection).\n",
      "-> [B2] Kiểm tra tính đầy đủ của Feature...\n",
      "   Yêu cầu: ['B04B', 'B10B', 'B11B', 'B16B', 'IRB', 'CAPE', 'R850', 'TCWV', 'U850', 'I2B', 'TCLW', 'TCW'] + ['y']\n",
      "\n",
      "========================================\n",
      "✅ KẾT QUẢ CUỐI CÙNG: 1223 mốc thời gian ĐỦ DỮ LIỆU.\n",
      "========================================\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:26:55.828157Z",
     "start_time": "2025-12-14T13:26:55.822767Z"
    }
   },
   "cell_type": "code",
   "source": "print(FINAL_TIMESTAMPS[:10])",
   "id": "bd58f0064f60f338",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2019-04-01 00:00:00'), Timestamp('2019-04-01 01:00:00'), Timestamp('2019-04-01 02:00:00'), Timestamp('2019-04-01 03:00:00'), Timestamp('2019-04-01 04:00:00'), Timestamp('2019-04-01 05:00:00'), Timestamp('2019-04-01 06:00:00'), Timestamp('2019-04-01 07:00:00'), Timestamp('2019-04-01 08:00:00'), Timestamp('2019-04-01 09:00:00')]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tải dữ liệu ranh giới tỉnh Thanh Hóa\n",
   "id": "e6b7abefe55e6a0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:26:55.881297Z",
     "start_time": "2025-12-14T13:26:55.834393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shp_path = \"gadm41_VNM_shp\"\n",
    "vnm_gdf = gpd.read_file(shp_path)\n",
    "\n",
    "th_gdf = vnm_gdf[vnm_gdf['VARNAME_1'] == 'Thanh Hoa']\n",
    "\n",
    "th_union = th_gdf.geometry.union_all()\n",
    "th_crs = th_gdf.crs"
   ],
   "id": "ffba14535edc54e2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# I. Xử lí Load ground Truth",
   "id": "a6c32ce71f1d11a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.Lấy các pixel chuẩn thuộc tỉnh Thanh Hóa",
   "id": "9232846a653a687a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "xử lí cho Y",
   "id": "39d215ab0e3531c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:26:55.892945Z",
     "start_time": "2025-12-14T13:26:55.887878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_ThanhHoa_pixels(path, root):\n",
    "    try:\n",
    "        with rasterio.open(path) as src:\n",
    "            data = src.read(1).astype(float)\n",
    "            nodata = src.nodata\n",
    "            transform = src.transform\n",
    "            src_crs = src.crs\n",
    "\n",
    "        # --- chuẩn hóa NODATA ---\n",
    "        data[data == nodata] = np.nan\n",
    "        data[data == -9999] = np.nan\n",
    "        data[np.isinf(data)] = np.nan\n",
    "\n",
    "        # --- fill nodata bằng nearest ---\n",
    "        data = fill_nodata_minus9999(data)\n",
    "\n",
    "        # --- reproject Hà Tĩnh sang CRS raster ---\n",
    "        if src_crs != th_crs:\n",
    "            geom = th_gdf.to_crs(src_crs).geometry.union_all()\n",
    "        else:\n",
    "            geom = th_union\n",
    "\n",
    "        # --- tạo mask pixel thuộc Thanh Hoas ---\n",
    "        mask = geometry_mask(\n",
    "            [mapping(geom)],\n",
    "            invert=True,\n",
    "            out_shape=data.shape,\n",
    "            transform=transform\n",
    "        )\n",
    "\n",
    "        rows, cols = np.where(mask)\n",
    "        vals = data[rows, cols]\n",
    "\n",
    "        # --- nếu không có pixel trong thanh hoa ---\n",
    "        if len(rows) == 0:\n",
    "            cr = data.shape[0] // 2\n",
    "            cc = data.shape[1] // 2\n",
    "            rows, cols = np.array([cr]), np.array([cc])\n",
    "            vals = np.array([data[cr, cc]])\n",
    "\n",
    "        # --- timestamp ---\n",
    "        ts = extract_datetime_from_filename(path)\n",
    "\n",
    "        # --- variable ---\n",
    "        rel = os.path.relpath(path, root)\n",
    "        var = rel.split(os.sep)[0]\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            \"variable\": var,\n",
    "            \"timestamp\": ts,\n",
    "            \"row\": rows,\n",
    "            \"col\": cols,\n",
    "            \"value\": vals\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR:\", path, e)\n",
    "        return pd.DataFrame({\n",
    "            \"variable\": \"unknown\",\n",
    "            \"timestamp\": pd.NaT,\n",
    "            \"row\": [0],\n",
    "            \"col\": [0],\n",
    "            \"value\": [np.nan],\n",
    "        })"
   ],
   "id": "7d6611e470e2dc24",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "xử lí cho X",
   "id": "d3bd8ce1e671840"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T14:20:06.426690Z",
     "start_time": "2025-12-14T14:20:06.360809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_ThanhHoa_bbox_all_pixels(path, root):\n",
    "    try:\n",
    "        with rasterio.open(path) as src:\n",
    "            data = src.read(1).astype(float)\n",
    "            nodata = src.nodata\n",
    "            transform = src.transform\n",
    "            src_crs = src.crs\n",
    "\n",
    "        # --- 1. Xử lý Nodata (vẫn giữ nguyên logic của bạn) ---\n",
    "        # Lưu ý: Nếu pixel bên ngoài tỉnh là nodata của ảnh gốc, nó sẽ thành nan ở đây\n",
    "        if nodata is not None:\n",
    "             data[data == nodata] = np.nan\n",
    "        data[data == -9999] = np.nan\n",
    "        data[np.isinf(data)] = np.nan\n",
    "\n",
    "        # Hàm này của bạn, giả định đã được define ở ngoài\n",
    "        data = fill_nodata_minus9999(data)\n",
    "\n",
    "        # --- 2. Chuẩn bị Geometry ---\n",
    "        # Lưu ý: th_crs, th_gdf, th_union phải là biến global hoặc truyền vào\n",
    "        if src_crs != th_crs:\n",
    "            geom = th_gdf.to_crs(src_crs).geometry.union_all()\n",
    "        else:\n",
    "            geom = th_union\n",
    "\n",
    "        # --- BƯỚC 1: Loose bbox (Khung bao quát) ---\n",
    "        bbox = geom.bounds\n",
    "        min_row_loose, min_col_loose = rasterio.transform.rowcol(transform, bbox[0], bbox[3])\n",
    "        max_row_loose, max_col_loose = rasterio.transform.rowcol(transform, bbox[2], bbox[1])\n",
    "\n",
    "        # Kẹp index trong phạm vi ảnh\n",
    "        min_row_loose = int(max(0, min_row_loose))\n",
    "        min_col_loose = int(max(0, min_col_loose))\n",
    "        max_row_loose = int(min(data.shape[0] - 1, max_row_loose))\n",
    "        max_col_loose = int(min(data.shape[1] - 1, max_col_loose))\n",
    "\n",
    "        # --- BƯỚC 2: Tạo Mask trong Loose bbox ---\n",
    "        height_loose = max_row_loose - min_row_loose + 1\n",
    "        width_loose = max_col_loose - min_col_loose + 1\n",
    "\n",
    "        # Tạo transform cho window con\n",
    "        window_transform = rasterio.windows.transform(\n",
    "            rasterio.windows.Window(min_col_loose, min_row_loose, width_loose, height_loose),\n",
    "            transform\n",
    "        )\n",
    "\n",
    "        # Mask: True = Nằm ngoài, False = Nằm trong (Mặc định rasterio)\n",
    "        # invert=True -> Mask sẽ trả về True nếu pixel nằm TRONG shape\n",
    "        mask_subset = geometry_mask(\n",
    "            [mapping(geom)],\n",
    "            invert=True,\n",
    "            out_shape=(height_loose, width_loose),\n",
    "            transform=window_transform\n",
    "        )\n",
    "\n",
    "        # --- BƯỚC 3: Tight bbox (Khung bao sát sạt pixel thật) ---\n",
    "        # Tìm các hàng/cột có chứa ít nhất 1 pixel thuộc tỉnh\n",
    "        valid_rows, valid_cols = np.where(mask_subset)\n",
    "\n",
    "        if len(valid_rows) == 0:\n",
    "            print(f\"WARNING: No pixel inside geometry: {path}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        trim_min_r, trim_max_r = valid_rows.min(), valid_rows.max()\n",
    "        trim_min_c, trim_max_c = valid_cols.min(), valid_cols.max()\n",
    "\n",
    "        # Tính lại toạ độ toàn cục (Global indices)\n",
    "        min_row = min_row_loose + trim_min_r\n",
    "        max_row = min_row_loose + trim_max_r\n",
    "        min_col = min_col_loose + trim_min_c\n",
    "        max_col = min_col_loose + trim_max_c\n",
    "\n",
    "        # --- BƯỚC 4: Lấy dữ liệu ---\n",
    "        # Tạo lưới toạ độ cho Tight Bbox\n",
    "        rows = np.arange(min_row, max_row + 1)\n",
    "        cols = np.arange(min_col, max_col + 1)\n",
    "\n",
    "        row_grid, col_grid = np.meshgrid(rows, cols, indexing='ij')\n",
    "        rows_flat = row_grid.flatten()\n",
    "        cols_flat = col_grid.flatten()\n",
    "\n",
    "        # Lấy giá trị từ dữ liệu gốc\n",
    "        # LƯU Ý: Ở đây 'vals' lấy trực tiếp từ 'data', nên nó giữ nguyên giá trị gốc\n",
    "        vals = data[rows_flat, cols_flat]\n",
    "\n",
    "        # Cắt mask tương ứng với Tight Bbox để biết điểm nào thuộc tỉnh, điểm nào không\n",
    "        mask_tight = mask_subset[\n",
    "            trim_min_r:trim_max_r + 1,\n",
    "            trim_min_c:trim_max_c + 1\n",
    "        ].flatten()\n",
    "\n",
    "        # --- ĐÃ XÓA ĐOẠN GÁN -1 Ở ĐÂY ---\n",
    "        # Trước đây: vals[~mask_tight] = -1  <-- XÓA DÒNG NÀY\n",
    "\n",
    "        ts = extract_datetime_from_filename(path)\n",
    "        rel = os.path.relpath(path, root)\n",
    "        var = rel.split(os.sep)[0]\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            \"variable\": var,\n",
    "            \"timestamp\": ts,\n",
    "            \"row\": rows_flat,\n",
    "            \"col\": cols_flat,\n",
    "            \"value\": vals,           # Giá trị gốc (có thể là NaN nếu là background của ảnh Tif)\n",
    "            \"is_inside_shape\": mask_tight # True: thuộc tỉnh, False: thuộc hcn bao quanh nhưng ngoài tỉnh\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR:\", path, e)\n",
    "        # In traceback để dễ debug hơn nếu cần\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return pd.DataFrame()"
   ],
   "id": "87eb42b4a58a48a4",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TIF THANH HÓA => CSV",
   "id": "2f09eda3276be08a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T14:20:07.452302Z",
     "start_time": "2025-12-14T14:20:07.439206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tif2csv_ThanhHoa(type):\n",
    "    output_file = OUTPUT_ERA5_CSV\n",
    "    root = ERA5_PATH\n",
    "\n",
    "    if type == \"radar\":\n",
    "        output_file = OUTPUT_RADAR_CSV\n",
    "        root = RADAR_PATH\n",
    "    elif type == \"hima\":\n",
    "        output_file = OUTPUT_HIMA_CSV\n",
    "        root = HIMA_PATH\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    files = list_all_files(root)\n",
    "    print(\"Tổng file tìm thấy:\", len(files))\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "\n",
    "    if type == \"era5\" or type == \"hima\":\n",
    "        func = partial(extract_ThanhHoa_bbox_all_pixels, root=root)\n",
    "    else:\n",
    "        func = partial(extract_ThanhHoa_pixels, root=root)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as pool:\n",
    "        futures = [pool.submit(func, f) for f in files]\n",
    "\n",
    "        for f in tqdm(as_completed(futures), total=len(futures), desc=\"Process\"):\n",
    "            try:\n",
    "                df = f.result()\n",
    "                if df is not None and not df.empty:\n",
    "                    results.append(df)\n",
    "            except Exception as e:\n",
    "                print(\"Thread error:\", e)\n",
    "\n",
    "    if results:\n",
    "        final = pd.concat(results, ignore_index=True)\n",
    "        final.to_csv(output_file, index=False)\n",
    "        print(\"DONE! Tổng pixel =\", len(final))\n",
    "    else:\n",
    "        print(\"Không có data.\")\n",
    "\n"
   ],
   "id": "801736c29fe0893d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tif2csv_ThanhHoa(\"radar\")",
   "id": "eeaf8c9332a6d949"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T14:42:48.309156Z",
     "start_time": "2025-12-14T14:20:27.729896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tif2csv_ThanhHoa(\"era5\")\n",
    "tif2csv_ThanhHoa(\"hima\")"
   ],
   "id": "1c2516e4a8f0eb71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng file tìm thấy: 58560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process: 100%|██████████| 58560/58560 [10:39<00:00, 91.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! Tổng pixel = 83623680\n",
      "Tổng file tìm thấy: 33064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process: 100%|██████████| 33064/33064 [04:15<00:00, 129.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE! Tổng pixel = 47215392\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# chuyển dữ liệu từ file.csv => numpy\n",
   "id": "94e1042e4405590a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T14:42:54.342428Z",
     "start_time": "2025-12-14T14:42:54.330807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_x_y_selected_features(list_path):\n",
    "\n",
    "    # 1) Đọc CSV và gộp\n",
    "    dfs = []\n",
    "    print(\"[B1] Đọc CSV...\")\n",
    "    for p in tqdm(list_path, desc=\"Đọc file CSV\"):\n",
    "        # Mẹo: Xác định dtype ngay lúc đọc để tiết kiệm bộ nhớ nếu file lớn\n",
    "        df = pd.read_csv(p)\n",
    "        df[\"variable\"] = df[\"variable\"].astype(str)\n",
    "        # Gán nhãn y\n",
    "        df.loc[df[\"variable\"].isin(['2019', '2020']), \"variable\"] = 'y'\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 2) Min/Max row/col → tạo hình chữ nhật\n",
    "    min_row, max_row = df_all[\"row\"].min(), df_all[\"row\"].max()\n",
    "    min_col, max_col = df_all[\"col\"].min(), df_all[\"col\"].max()\n",
    "    n_row = int(max_row - min_row + 1)\n",
    "    n_col = int(max_col - min_col + 1)\n",
    "\n",
    "    # 3) Xác định danh sách band cần thiết (QUAN TRỌNG: Phải Sort để cố định thứ tự)\n",
    "    required_bands_list = sorted(list(set(selected_features + ['y'])))\n",
    "    required_bands_set = set(required_bands_list)\n",
    "    print(f\"-> Số lượng band bắt buộc: {len(required_bands_list)}\")\n",
    "\n",
    "    # 4) Lọc Timestamp hợp lệ (TỐI ƯU HÓA TỐC ĐỘ)\n",
    "    print(\"[B2] Lọc timestamp đầy đủ (Vectorized Check)...\")\n",
    "\n",
    "    # Chỉ giữ lại các dòng thuộc các variable quan tâm để đếm cho nhanh\n",
    "    df_check = df_all[df_all[\"variable\"].isin(required_bands_set)]\n",
    "\n",
    "    # Đếm số lượng variable unique trong mỗi timestamp\n",
    "    # Nếu timestamp T1 có đủ 13 variable -> count sẽ là 13\n",
    "    ts_counts = df_check.groupby(\"timestamp\")[\"variable\"].nunique()\n",
    "\n",
    "    # Lấy ra các timestamp có số lượng variable bằng đúng số lượng yêu cầu\n",
    "    valid_ts_index = ts_counts[ts_counts == len(required_bands_set)].index\n",
    "    ts_valid = sorted(list(valid_ts_index))\n",
    "\n",
    "    print(f\"-> Tìm thấy {len(ts_valid)} timestamp hợp lệ.\")\n",
    "\n",
    "    # 5) Chuẩn bị dữ liệu để đổ vào Tensor\n",
    "    print(\"[B3] Chuẩn bị index và Tensor...\")\n",
    "\n",
    "    # Tạo mapping index (Dictionary comprehension)\n",
    "    t_to_idx = {t: i for i, t in enumerate(ts_valid)}\n",
    "    b_to_idx = {b: i for i, b in enumerate(required_bands_list)} # Dùng list đã sort\n",
    "\n",
    "    # Lọc dữ liệu chính thức:\n",
    "    # - Chỉ lấy timestamp hợp lệ\n",
    "    # - Chỉ lấy variable nằm trong required_bands (Bước này sửa lỗi Index Float)\n",
    "    df_valid = df_all[\n",
    "        (df_all[\"timestamp\"].isin(ts_valid)) &\n",
    "        (df_all[\"variable\"].isin(required_bands_set))\n",
    "    ].copy()\n",
    "\n",
    "    # Map sang index (Ép kiểu int rõ ràng để tránh lỗi)\n",
    "    df_valid[\"t_idx\"] = df_valid[\"timestamp\"].map(t_to_idx).astype(int)\n",
    "    df_valid[\"b_idx\"] = df_valid[\"variable\"].map(b_to_idx).astype(int)\n",
    "    df_valid[\"r_idx\"] = (df_valid[\"row\"] - min_row).astype(int)\n",
    "    df_valid[\"c_idx\"] = (df_valid[\"col\"] - min_col).astype(int)\n",
    "\n",
    "    # 6) Đổ dữ liệu vào Tensor (Vectorized - Không cần vòng lặp)\n",
    "    print(\"[B4] Đổ dữ liệu vào Tensor...\")\n",
    "\n",
    "    tensor = np.full(\n",
    "        (len(ts_valid), len(required_bands_list), n_row, n_col),\n",
    "        -1,\n",
    "        dtype=float\n",
    "    )\n",
    "\n",
    "    # Numpy Advanced Indexing: Nhanh hơn loop rất nhiều\n",
    "    tensor[df_valid[\"t_idx\"].values,\n",
    "           df_valid[\"b_idx\"].values,\n",
    "           df_valid[\"r_idx\"].values,\n",
    "           df_valid[\"c_idx\"].values] = df_valid[\"value\"].values\n",
    "\n",
    "    # 7) Tách X và y\n",
    "    y_idx = b_to_idx['y']\n",
    "    # Lấy mảng X indices: loại bỏ index của y\n",
    "    x_indices = [i for i, b in enumerate(required_bands_list) if b != 'y']\n",
    "\n",
    "    y = tensor[:, [y_idx], :, :]\n",
    "    x = tensor[:, x_indices, :, :]\n",
    "\n",
    "    return x, y, ts_valid, required_bands_list, (min_row, max_row), (min_col, max_col)"
   ],
   "id": "578becea72ed2041",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T14:44:24.427649Z",
     "start_time": "2025-12-14T14:42:55.095560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def luuTensor():\n",
    "    list_file = [\n",
    "        OUTPUT_HIMA_CSV,\n",
    "        OUTPUT_ERA5_CSV,\n",
    "        OUTPUT_RADAR_CSV\n",
    "    ]\n",
    "\n",
    "    x, y, timestamps, x_bands, row_range, col_range = create_x_y_selected_features(list_file)\n",
    "\n",
    "    print(\"[B4] Lưu tensor...\")\n",
    "    np.save(OUTPUT_X, x)\n",
    "    np.save(OUTPUT_Y, np.squeeze(y, axis=1))\n",
    "\n",
    "luuTensor()"
   ],
   "id": "4a3d061c0271fc3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[B1] Đọc CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Đọc file CSV: 100%|██████████| 3/3 [00:54<00:00, 18.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Số lượng band bắt buộc: 13\n",
      "[B2] Lọc timestamp đầy đủ (Vectorized Check)...\n",
      "-> Tìm thấy 1223 timestamp hợp lệ.\n",
      "[B3] Chuẩn bị index và Tensor...\n",
      "[B4] Đổ dữ liệu vào Tensor...\n",
      "[B4] Lưu tensor...\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:48:21.604897Z",
     "start_time": "2025-12-14T13:48:21.599381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def check_data_stats(csv_path):\n",
    "#     print(f\"Dang doc file: {csv_path} ...\")\n",
    "#\n",
    "#     try:\n",
    "#         # Load file CSV\n",
    "#         df = pd.read_csv(csv_path)\n",
    "#\n",
    "#         # Lấy cột giá trị (thường tên là 'value')\n",
    "#         if 'value' not in df.columns:\n",
    "#             print(\"Lỗi: Không tìm thấy cột 'value' trong CSV.\")\n",
    "#             print(\"Các cột hiện có:\", df.columns)\n",
    "#             return\n",
    "#\n",
    "#         total_pixels = len(df)\n",
    "#         if total_pixels == 0:\n",
    "#             print(\"File rỗng! Không có dữ liệu.\")\n",
    "#             return\n",
    "#\n",
    "#         # 1. Đếm số lượng số 0\n",
    "#         zero_count = (df['value'] == 0).sum()\n",
    "#         zero_ratio = (zero_count / total_pixels) * 100\n",
    "#\n",
    "#         # 2. Đếm số lượng NaN (dữ liệu lỗi/thiếu)\n",
    "#         nan_count = df['value'].isna().sum()\n",
    "#         nan_ratio = (nan_count / total_pixels) * 100\n",
    "#\n",
    "#         # 3. Tìm giá trị lớn nhất (để xem có mưa thật không)\n",
    "#         max_val = df['value'].max()\n",
    "#         min_val = df['value'].min()\n",
    "#         mean_val = df['value'].mean()\n",
    "#\n",
    "#         # --- IN KẾT QUẢ ---\n",
    "#         print(\"-\" * 30)\n",
    "#         print(\"BÁO CÁO THỐNG KÊ DỮ LIỆU\")\n",
    "#         print(\"-\" * 30)\n",
    "#         print(f\"Tổng số dòng (pixels): {total_pixels:,}\")\n",
    "#         print(f\"Giá trị MAX (Mưa lớn nhất): {max_val}\")\n",
    "#         print(f\"Giá trị MIN: {min_val}\")\n",
    "#         print(f\"Giá trị Trung bình: {mean_val:.4f}\")\n",
    "#         print(\"-\" * 30)\n",
    "#         print(f\"Số lượng điểm = 0: {zero_count:,} ({zero_ratio:.2f}%)\")\n",
    "#         print(f\"Số lượng điểm NaN: {nan_count:,} ({nan_ratio:.2f}%)\")\n",
    "#         print(\"-\" * 30)\n",
    "#\n",
    "#         # --- ĐÁNH GIÁ SƠ BỘ ---\n",
    "#         if zero_ratio == 100:\n",
    "#             print(\"⚠️ CẢNH BÁO: Dữ liệu toàn số 0. Kiểm tra lại code trích xuất!\")\n",
    "#         elif zero_ratio > 90:\n",
    "#             print(\"ℹ️ LƯU Ý: Tỉ lệ số 0 rất cao (>90%). Điều này BÌNH THƯỜNG nếu là dữ liệu mưa (mưa thưa).\")\n",
    "#         elif max_val == 0:\n",
    "#             print(\"⚠️ CẢNH BÁO: Max value = 0. Có vẻ như không có chút mưa nào được ghi nhận.\")\n",
    "#         else:\n",
    "#             print(\"✅ Dữ liệu trông có vẻ hợp lý.\")\n",
    "#\n",
    "#     except Exception as e:\n",
    "#         print(f\"Có lỗi khi đọc file: {e}\")\n",
    "#\n",
    "#\n",
    "# # --- CÁCH SỬ DỤNG ---\n",
    "# # Thay đường dẫn file CSV của bạn vào đây\n",
    "# csv_file_path = OUTPUT_Y_CSV  # Biến này bạn đã khai báo ở đoạn code trước\n",
    "# check_data_stats(csv_file_path)"
   ],
   "id": "525929595ee71194",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CSV PIXEL THANH HÓA => NUMPY",
   "id": "66942a7efc40d70d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:48:21.625532Z",
     "start_time": "2025-12-14T13:48:21.618990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def csv2numpy_thanhhoa(list_path):\n",
    "\n",
    "    # 1) Đọc CSV và gộp\n",
    "    dfs = []\n",
    "    print(\"[B1] Đọc CSV...\")\n",
    "    for p in tqdm(list_path, desc=\"Đọc file CSV\"):\n",
    "        # Mẹo: Xác định dtype ngay lúc đọc để tiết kiệm bộ nhớ nếu file lớn\n",
    "        df = pd.read_csv(p)\n",
    "        df[\"variable\"] = df[\"variable\"].astype(str)\n",
    "        # Gán nhãn y\n",
    "        df.loc[df[\"variable\"].isin(['2019', '2020']), \"variable\"] = 'y'\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 2) Min/Max row/col → tạo hình chữ nhật\n",
    "    min_row, max_row = df_all[\"row\"].min(), df_all[\"row\"].max()\n",
    "    min_col, max_col = df_all[\"col\"].min(), df_all[\"col\"].max()\n",
    "    n_row = int(max_row - min_row + 1)\n",
    "    n_col = int(max_col - min_col + 1)\n",
    "\n",
    "    # 3) Xác định danh sách band cần thiết (QUAN TRỌNG: Phải Sort để cố định thứ tự)\n",
    "    required_bands_list = sorted(list(set(selected_features + ['y'])))\n",
    "    required_bands_set = set(required_bands_list)\n",
    "    print(f\"-> Số lượng band bắt buộc: {len(required_bands_list)}\")\n",
    "\n",
    "    # 4) Lọc Timestamp hợp lệ (TỐI ƯU HÓA TỐC ĐỘ)\n",
    "    print(\"[B2] Lọc timestamp đầy đủ (Vectorized Check)...\")\n",
    "\n",
    "    # Chỉ giữ lại các dòng thuộc các variable quan tâm để đếm cho nhanh\n",
    "    df_check = df_all[df_all[\"variable\"].isin(required_bands_set)]\n",
    "\n",
    "    # Đếm số lượng variable unique trong mỗi timestamp\n",
    "    # Nếu timestamp T1 có đủ 13 variable -> count sẽ là 13\n",
    "    ts_counts = df_check.groupby(\"timestamp\")[\"variable\"].nunique()\n",
    "\n",
    "    # Lấy ra các timestamp có số lượng variable bằng đúng số lượng yêu cầu\n",
    "    valid_ts_index = ts_counts[ts_counts == len(required_bands_set)].index\n",
    "    ts_valid = sorted(list(valid_ts_index))\n",
    "\n",
    "    print(f\"-> Tìm thấy {len(ts_valid)} timestamp hợp lệ.\")\n",
    "\n",
    "    # 5) Chuẩn bị dữ liệu để đổ vào Tensor\n",
    "    print(\"[B3] Chuẩn bị index và Tensor...\")\n",
    "\n",
    "    # Tạo mapping index (Dictionary comprehension)\n",
    "    t_to_idx = {t: i for i, t in enumerate(ts_valid)}\n",
    "    b_to_idx = {b: i for i, b in enumerate(required_bands_list)} # Dùng list đã sort\n",
    "\n",
    "    # Lọc dữ liệu chính thức:\n",
    "    # - Chỉ lấy timestamp hợp lệ\n",
    "    # - Chỉ lấy variable nằm trong required_bands (Bước này sửa lỗi Index Float)\n",
    "    df_valid = df_all[\n",
    "        (df_all[\"timestamp\"].isin(ts_valid)) &\n",
    "        (df_all[\"variable\"].isin(required_bands_set))\n",
    "    ].copy()\n",
    "\n",
    "    # Map sang index (Ép kiểu int rõ ràng để tránh lỗi)\n",
    "    df_valid[\"t_idx\"] = df_valid[\"timestamp\"].map(t_to_idx).astype(int)\n",
    "    df_valid[\"b_idx\"] = df_valid[\"variable\"].map(b_to_idx).astype(int)\n",
    "    df_valid[\"r_idx\"] = (df_valid[\"row\"] - min_row).astype(int)\n",
    "    df_valid[\"c_idx\"] = (df_valid[\"col\"] - min_col).astype(int)\n",
    "\n",
    "    # 6) Đổ dữ liệu vào Tensor (Vectorized - Không cần vòng lặp)\n",
    "    print(\"[B4] Đổ dữ liệu vào Tensor...\")\n",
    "    # tensor = np.zeros((len(ts_valid), len(required_bands_list), n_row, n_col), dtype=float)\n",
    "\n",
    "    tensor = np.full(\n",
    "        (len(ts_valid), len(required_bands_list), n_row, n_col),\n",
    "        -1,\n",
    "        dtype=float\n",
    "    )\n",
    "\n",
    "    # Numpy Advanced Indexing: Nhanh hơn loop rất nhiều\n",
    "    tensor[df_valid[\"t_idx\"].values,\n",
    "           df_valid[\"b_idx\"].values,\n",
    "           df_valid[\"r_idx\"].values,\n",
    "           df_valid[\"c_idx\"].values] = df_valid[\"value\"].values\n",
    "\n",
    "    # 7) Tách X và y\n",
    "    y_idx = b_to_idx['y']\n",
    "    # Lấy mảng X indices: loại bỏ index của y\n",
    "    x_indices = [i for i, b in enumerate(required_bands_list) if b != 'y']\n",
    "\n",
    "    y = tensor[:, [y_idx], :, :]\n",
    "    x = tensor[:, x_indices, :, :]\n",
    "\n",
    "    return x, y, ts_valid, required_bands_list, (min_row, max_row), (min_col, max_col)"
   ],
   "id": "c61124aed9272437",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:48:21.637799Z",
     "start_time": "2025-12-14T13:48:21.634506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Gọi hàm y như cũ, nó sẽ tự trả về tensor 3 chiều\n",
    "# list_path_csv = [OUTPUT_Y_CSV]\n",
    "# tensor_3d, times, bands, row_range, col_range = csv2numpy_thanhhoa(list_path_csv)\n",
    "#\n",
    "# # Kiểm tra shape\n",
    "# print(tensor_3d.shape)\n",
    "# # Kết quả sẽ là: (Số lượng Time, Số lượng Row, Số lượng Col)"
   ],
   "id": "efb3625a30460731",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T13:48:21.648442Z",
     "start_time": "2025-12-14T13:48:21.645591Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a45130de72db4a34",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
